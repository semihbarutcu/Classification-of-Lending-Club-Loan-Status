---
title: "Term Project"
author: "Semih Barutcu"
date: "2/17/2020"
output:
  pdf_document: default
  html_document: default
---

```{r warning=FALSE, message=FALSE}
library(pacman)
p_load(dplyr, tidyverse, lubridate, Amelia, vtable, tictoc, rpart, rpart.plot, C50, ROCR, 
       caret, randomForest, tictoc, ranger, class, gmodels, naivebayes)
```

In this project, Lending Club accepted loan data was studied. Loan status was response variable and I worked on both 84 remaining variable and selected 10 remaining variable. Machine Learning algorithms implementations and results can be seen below step by step.


## Step 1 – Reading the data

```{r warning=FALSE, message=F}
LendingClub  <- read_csv("accepted_2007_to_2018Q4.csv") %>% mutate_if(is.character, as.factor)
```

I eliminated some variables because they are identifier variables train data which possibly overfit. Also, some of variables are not selected because of impractical to use and including excessive NA values. 
```{r}
#Defining year from issue_d and make it integer
LendingClub$year <- str_sub(LendingClub$issue_d, start=-4) %>% as.integer(LendingClub$year)

LendingClub_2012to2014 <- LendingClub %>% 
  filter(between(year,2012,2014)) %>% 
  select(-id, -member_id, -emp_title, -issue_d, -url, -desc, -zip_code, -title, 
         -earliest_cr_line, -last_pymnt_d, -last_credit_pull_d) 
  
LendingClub_2012to2014 <- LendingClub_2012to2014[, colMeans(is.na(LendingClub_2012to2014)) < 0.2]


LendingClub_2012to2014v2 <- LendingClub %>% 
  filter(between(year,2012,2014)) %>% 
  select(loan_status, funded_amnt, emp_length, annual_inc, last_pymnt_amnt, mort_acc, 
         int_rate, mo_sin_old_rev_tl_op, avg_cur_bal, acc_open_past_24mths, num_bc_sats) 
```

The dataset, which had 11 total variable, was named as v2 at the end of LendingClub, train and test data frames. These variables were selected according to ease of use them and I focused mostly numeric values. Table of variables can be seen below. There are 376,516 rows.
```{r}
vtable(LendingClub_2012to2014v2, out = 'return')
nrow(LendingClub_2012to2014v2)
```


## Step 2 – Exploring and preparing the data

From loan_status table, we can see that 3 results were observed at most. I filtered the data just for these options to get more accurate results.

On the first graph, loan status were depicted according to count of funded amounts and faceted by term. 36 months loan users had a right skewed distribution while 60 months users had an uneven distribution.

On the first graph, loan status were depicted according to count of interest rate and faceted by term. 36 months loan users had a right skewed distribution again while 60 months users had normal distribution.

We can see that 60 months term loan users had higher rate of charged off from table and graphs.
```{r}
table(LendingClub_2012to2014$loan_status, LendingClub_2012to2014$term)

LendingClub_2012to2014 %>% 
  ggplot(aes(funded_amnt, fill = loan_status)) +
  geom_histogram(bins = 10) +
  scale_fill_brewer(palette = "Dark2", direction = -1) +
  facet_wrap(~term) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

LendingClub_2012to2014 %>% 
  ggplot(aes(int_rate, fill = loan_status)) +
  geom_histogram(bins = 10) +
  scale_fill_brewer(palette = "Dark2", direction = -1) +
  facet_wrap(~term) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))


LendingClub_2012to2014 <- LendingClub_2012to2014 %>% 
  filter(loan_status == "Charged Off" | loan_status == "Current" | loan_status == "Fully Paid") %>% na.omit()

LendingClub_2012to2014v2 <- LendingClub_2012to2014v2 %>% 
  filter(loan_status == "Charged Off" | loan_status == "Current" | loan_status == "Fully Paid") %>% na.omit()
```

Train and test data were created below with a 10000 and 2500 samples from the main data which resulted similar proportion of distribution with the main data. After all my work has done, I set a seed to interpret final results exactly.
```{r}
set.seed(123)
idx1 <- sample(nrow(LendingClub_2012to2014v2), 10000)
idx2 <- sample(nrow(LendingClub_2012to2014v2), 2500)

idx <- sample(nrow(LendingClub_2012to2014v2), round(0.75*nrow(LendingClub_2012to2014v2)))

train <- LendingClub_2012to2014[idx1,]
test <- LendingClub_2012to2014[idx2,]

trainv2 <- LendingClub_2012to2014v2[idx1,]
testv2 <- LendingClub_2012to2014v2[idx2,]
```

Levels of factor variable are reduced to 3 different types for loan status below.
```{r}
levels(trainv2$loan_status)

trainv2$loan_status <- factor(trainv2$loan_status)
levels(trainv2$loan_status)

testv2$loan_status <- factor(testv2$loan_status)
```


## Step 3 – Training models

### Null Model

Proportions of loan status for train and test datasets can be seen below. Fully paid had proportions between 80% and 82% for samples. We have to consider dominance of this property on machine learning algorithms.
```{r}
trainv2 %>% 
  group_by(loan_status) %>%
  summarise(n = n()) %>%
  mutate(freq = n/sum(n))

testv2 %>% 
  group_by(loan_status) %>%
  summarise(n = n()) %>%
  mutate(freq = n/sum(n))
```


### kNN

kNN method was implemented after required normalization. I chose k as 4 firstly. The accuracies were 85.88% and 77.68% for train and test data respectively. Detailed proportions can be seen on CrossTable. Over-fitting is on the acceptable range for kNN method.
```{r}
# Normalization function
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# Prepare data
train_knnv2 <- trainv2 %>% mutate_if(is.factor, as.numeric)
test_knnv2 <- testv2 %>% mutate_if(is.factor, as.numeric)

# Normalization
train_knnv2n  <- as.data.frame(lapply(train_knnv2[2:11], normalize))
test_knnv2n  <- as.data.frame(lapply(test_knnv2[2:11], normalize))

# Prediction for train data
pred_knntrainv2 <- knn(train_knnv2n, train_knnv2n, cl= train_knnv2$loan_status, k=4)

# Evaluating model performance
CrossTable(x = train_knnv2$loan_status, y = pred_knntrainv2,
           prop.chisq = FALSE)

mean(train_knnv2$loan_status == pred_knntrainv2)

# Prediction for test data
pred_knntestv2 <- knn(train_knnv2n, test_knnv2n, cl= train_knnv2$loan_status, k=4)

# Evaluating model performance
CrossTable(x = test_knnv2$loan_status, y = pred_knntestv2,
           prop.chisq = FALSE)

mean(test_knnv2$loan_status == pred_knntestv2)
```

This time, I tried to find effect of different k values via a for loop. I excluded CrossTable this time for ease of readability. Plots of accuracies can be seen below. Train data had perfect fit when k is equal to 1 while test data had lowest accuracy rate. With increasing k value, accuracy of train data decreases and accuracy of test data increases. On the other hand, we should consider that increasing k value may cause to domination by fully paid results while low value of k cause augmented local influence. So, k should be between 3 and 4 to get more accurate predictions while we can arrange any other k up to cost of decisions. Decision maker should consider total profit for his case.
```{r}
# Normalization function
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}


tic()

# Prepare data
mean_knn <- c()
train_knnv2 <- trainv2 %>% 
  mutate_if(is.factor, as.numeric) %>% 
  select(loan_status, everything()) 

test_knnv2 <- testv2 %>% 
  mutate_if(is.factor, as.numeric) %>% 
  select(loan_status, everything()) 

# Normalization
train_knnv2n  <- as.data.frame(lapply(train_knnv2[2:11], normalize))
test_knnv2n  <- as.data.frame(lapply(test_knnv2[2:11], normalize))


# Loop for train data
for (k in c(1:20)) {
pred_knntrainv2 <- knn(train_knnv2n, train_knnv2n, cl= train_knnv2$loan_status, k=k)

mean_knn[k] <- mean(train_knnv2$loan_status == pred_knntrainv2) 
  
}
# Evaluating model performance
plot(mean_knn)
mean_knn
toc()

# Loop for test data
for (k in c(1:20)) {
pred_knntestv2 <- knn(train_knnv2n, test_knnv2n, cl= train_knnv2$loan_status, k=k)

mean_knn[k] <- mean(test_knnv2$loan_status == pred_knntestv2) 
  
}
# Evaluating model performance
plot(mean_knn)
mean_knn
toc()
```


### Boosted C5.0

One of the best way to learn loans is classification trees. Default decision tree via C5.0 can be seen below.
```{r}
train_c50 <- trainv2 %>% select(-emp_length)
test_c50 <- testv2 %>% select(-emp_length)

modelc50 <- C5.0(train_c50[,-1], train_c50$loan_status)

modelc50
summary(modelc50)
```

```{r}
fittedc50train <- predict(modelc50, newdata = train_c50)

print(paste('Accuracy for train:', mean(fittedc50train == trainv2$loan_status)))

# test

fittedc50test <- predict(modelc50, newdata = test_c50)

print(paste('Accuracy for test:', mean(fittedc50test == testv2$loan_status)))
```


C5.0 could be developed by boosting. I excluded summary of the new model because of ease of readability.
```{r}
## Boosting the accuracy of decision trees
# boosted decision tree with 10 trials

modelc50boosted <- C5.0(train_c50[,-1], train_c50$loan_status, trials = 10)

modelc50boosted
#summary(modelc50boosted)
```


```{r}
fittedc50trainboosted <- predict(modelc50boosted, newdata = train_c50)

print(paste('Accuracy for boosted train data:', mean(fittedc50trainboosted == trainv2$loan_status)))

# test

fittedc50testboosted <- predict(modelc50boosted, newdata = test_c50)

print(paste('Accuracy for boosted test data:', mean(fittedc50testboosted == testv2$loan_status)))
```


### Random Forest

Accuracy is perfect for the train dataset. accuracy is 84.64% for test data.
```{r}
tic()
rf <- randomForest(loan_status ~ ., data = trainv2)

rf
summary(rf)

rf_predtrain <- predict(rf, trainv2)
confusionMatrix(data=rf_predtrain, trainv2$loan_status)

rf_predtest <- predict(rf, testv2)
confusionMatrix(data=rf_predtest, testv2$loan_status)


err <- rf$err.rate
oob_err <- err[nrow(err), "OOB"]
plot(rf)
legend(x = "right", 
       legend = colnames(err),
       fill = 1:ncol(err))

toc()
```

### Random Forest via ranger

Accuracy is perfect for the train dataset. Accuracy is 84.64% for test dataset again by ranger package. 
```{r}
tic()
rfranger <- ranger(loan_status ~ ., data = trainv2, num.threads = 4 )

rfranger

rfranger$confusion.matrix

summary(rfranger)

rf_predrangertrain <- predict(rfranger, trainv2)

confusionMatrix(data=rf_predrangertrain$predictions, trainv2$loan_status)

rf_predrangertest <- predict(rfranger, testv2)

confusionMatrix(data=rf_predrangertest$predictions, testv2$loan_status)
toc()
```

## Conclusion

3 different algorithms were implemented to the data. 1 alternative way and 1 boosting method were used to check and improve models. kNN method had least accurate results for test data while random forests had best which is 84.64%. Ranger gave same results with randomForest package but execution time was smaller, 2.91 sec vs 18.99 sec respectively.  C5.0 method results very close to random forest while boosting does not help to improve accuracy of outcomes. 





